{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EdgeComputingTP6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN7OcrBTVLEx",
        "outputId": "a10f814e-1c9f-4aba-d27f-538a99fd99c3"
      },
      "source": [
        "!pip install --upgrade git+git://github.com/glemercier/nvcc4jupyter.git\n",
        "%reload_ext nvcc_plugin"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/glemercier/nvcc4jupyter.git\n",
            "  Cloning git://github.com/glemercier/nvcc4jupyter.git to /tmp/pip-req-build-ajygr2cb\n",
            "  Running command git clone -q git://github.com/glemercier/nvcc4jupyter.git /tmp/pip-req-build-ajygr2cb\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4348 sha256=fa74afea00c9614873a45612cfa03b3363cd01e802d88170b68646f6288780f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tzo1933f/wheels/5e/23/ce/1e8885fe85a348e1208703a748142f57551cbefc18e4e05537\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "  Found existing installation: NVCCPlugin 0.0.2\n",
            "    Uninstalling NVCCPlugin-0.0.2:\n",
            "      Successfully uninstalled NVCCPlugin-0.0.2\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "directory /content/src already exists\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJelubWFOvMK"
      },
      "source": [
        "!mkdir -p /tmp/tp6\n",
        "!wget --quiet https://github.com/glemercier/nvcc4jupyter/releases/download/tp6/data1.bin -P /tmp/tp6\n",
        "!wget --quiet https://github.com/glemercier/nvcc4jupyter/releases/download/tp6/data2.bin -P /tmp/tp6\n",
        "!wget --quiet https://github.com/glemercier/nvcc4jupyter/releases/download/tp6/data3.bin -P /tmp/tp6\n",
        "!wget --quiet https://github.com/glemercier/nvcc4jupyter/releases/download/tp6/data4.bin -P /tmp/tp6\n",
        "!wget --quiet https://github.com/glemercier/nvcc4jupyter/releases/download/tp6/image-edf.jpg -P /tmp/tp6"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgbVeA47Vjkv",
        "outputId": "4ab38f3d-9cda-4faf-ed96-7034889ff4c0"
      },
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <algorithm>                                                                                                    \n",
        "#include <numeric>                                                                                                      \n",
        "#include <cmath>\n",
        "#include <cassert>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "#include <opencv2/opencv.hpp>\n",
        "#include <cuda_runtime_api.h>\n",
        "\n",
        "#define CUDA_ASSERT(x)  assert(x == cudaSuccess)\n",
        "\n",
        "std::vector<float> loadData(const std::string &fileName);\n",
        "bool compareImages(const cv::Mat &a, const cv::Mat &b);\n",
        "\n",
        "//# Compute the distances between inputs and store them ino the 'distance' array. 'size' is the number                   \n",
        "//# of elements in the arrays (here it's 512):                                                                           \n",
        "//#                                                                                                                     \n",
        "//# distance[0] = distance(a, b)                                                                                         \n",
        "//# distance[1] = distance(a, c)                                                                                         \n",
        "//# distance[2] = distance(a, d)                                                                                         \n",
        "//#                                                                                                                     \n",
        "//# The distance between two arrays a and b  is computed as per the formula:                                             \n",
        "//#  distance = square_root(sum(pow2(a - b)))                                                                           \n",
        "//#                                                                                                                     \n",
        "//# See 'distanceCpu' for CPU implementation\n",
        "__global__ void distanceCudaKernel(const float *a, float *b, float *sum, int size) {\n",
        "    int idx = threadIdx.x + (blockIdx.x * blockDim.x);\n",
        "\n",
        "    __shared__ unsigned int sum;\n",
        "\n",
        "    // # one of the threads will initialize sum to 0\n",
        "    if(idx == 0) {\n",
        "        sum = 0;\n",
        "    }\n",
        "\n",
        "    // # Sync all thread\n",
        "    if(idx < size){\n",
        "        float dis = powf(a[idx] - b[idx], 2.0f);\n",
        "\n",
        "        // # add dis to sum\n",
        "        sum += dis;\n",
        "    }\n",
        "}\n",
        "\n",
        "void distanceGpu(const float *a, const float *b, const float *c, float *d, float *sum, int size) {\n",
        "  //# To be implemented ...   \n",
        "  const int THREADS_PER_BLOCK = 128; // # Can be fine-tuned for better performance\n",
        "  const int NUMBER_OF_BLOCKS = (size + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK; // # Round Up\n",
        "  distanceCudaKernel<<<NUMBER_OF_BLOCKS, THREADS_PER_BLOCK>>>(a, b, sum, size);\n",
        "\n",
        "  sum => array of 512 floats;\n",
        "  sumCudaKernel<<<1, 1>>>();                      \n",
        "}\n",
        "\n",
        "//# Cast the pixels contained in 'inputImage' from uint8_t to float and normalize the R,G,B components                   \n",
        "//# of each pixel around 0.5 as per the following formula: a = ((a / 255)  - 0.5) / 0.5                                  \n",
        "//# Return the resulting image as a pointer to a GPU buffer allocated by the function.                                   \n",
        "//# 'size' is the number of pixels * 3 channels of the image, or the number of total elements stored                     \n",
        "//# in the array. See 'preprocessCpu' for CPU implementation.    \n",
        "\n",
        "__global__ void preprocessCudaKernel(const uint8_t *in, float *out, int size) {\n",
        "    // # Get the index corresponding to the computation unit where this kernel is running\n",
        "    int idx = threadIdx.x + (blockIdx.x * blockDim.x);\n",
        "\n",
        "    if(idx < size){\n",
        "        out[idx] = (float)in[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "void preprocessGpu(const uint8_t *inputImage, int size, float *out) {\n",
        "  //# To be implemented...\n",
        "  const int NUMBER_OF_BLOCKS = 128; // # Can be fine-tuned for better performance\n",
        "  const int THREADS_PER_BLOCK = (NUMBER_OF_BLOCKS + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK; // # Round Up\n",
        "  preprocessCudaKernel<<<NUMBER_OF_BLOCKS, THREADS_PER_BLOCK>>>(inputImage, out, size);\n",
        "}\n",
        "\n",
        "cv::Mat preprocessCpu(const cv::Mat &inputImage) {\n",
        "  cv::Mat out;   \n",
        "  inputImage.convertTo(out, CV_32F);\n",
        "\n",
        "  out.forEach<cv::Point3_<float>>([](cv::Point3_<float> &p, const int pos[]) -> void {                                                  \n",
        "    p.x = ((p.x / 255.0f) - 0.5f) / 0.5f;\n",
        "    p.y = ((p.y / 255.0f) - 0.5f) / 0.5f; \n",
        "    p.z = ((p.z / 255.0f) - 0.5f) / 0.5f;                                                                                     \n",
        "  });\n",
        "\n",
        "  return out;\n",
        "}\n",
        "\n",
        "inline float distanceCpu(const std::vector<float>& a, const std::vector<float>& b) {\n",
        "  float dis = 0.0f;\n",
        "  for (int i = 0; i < a.size(); i++) {\n",
        "    dis += std::pow(a[i] - b[i], 2);\n",
        "  }\n",
        "  return std::sqrt(dis);   \n",
        "}\n",
        "\n",
        "std::array<float, 3> distanceCpu(const std::vector<float>& a, const std::vector<float>& b,\n",
        "      const std::vector<float>& c, const std::vector<float>& d) {\n",
        "  return {\n",
        "    distanceCpu(a, b),\n",
        "    distanceCpu(a, c),\n",
        "    distanceCpu(a, d)\n",
        "  };                                                                                      \n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "T* CopyToGpuMem(const std::vector<T> &vec) {\n",
        "  T *ptr;\n",
        "  CUDA_ASSERT(cudaMalloc(&ptr, vec.size() * sizeof(T)));\n",
        "  CUDA_ASSERT(cudaMemcpy(ptr, vec.data(), vec.size() * sizeof(T), cudaMemcpyHostToDevice));\n",
        "  return ptr;\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "T* CopyToGpuMem(const cv::Mat &mat) {\n",
        "  T *ptr;\n",
        "  CUDA_ASSERT(cudaMalloc(&ptr, mat.total() * mat.channels() * sizeof(T)));\n",
        "  CUDA_ASSERT(cudaMemcpy(ptr, mat.data, mat.total() * mat.channels() * sizeof(T), cudaMemcpyHostToDevice));\n",
        "  return ptr;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  // Load input data\n",
        "  std::vector<float> a = loadData(\"/tmp/tp6/data1.bin\");\n",
        "  std::vector<float> b = loadData(\"/tmp/tp6/data2.bin\");\n",
        "  std::vector<float> c = loadData(\"/tmp/tp6/data3.bin\");\n",
        "  std::vector<float> d = loadData(\"/tmp/tp6/data4.bin\");\n",
        "  assert(a.size() == b.size());\n",
        "  assert(a.size() == c.size());\n",
        "  assert(a.size() == d.size());\n",
        "  cv::Mat image = cv::imread(\"/tmp/tp6/image-edf.jpg\");\n",
        "  assert(image.data != nullptr);\n",
        "  assert(image.type() == CV_8UC3);\n",
        "\n",
        "  // Copy data to GPU memory\n",
        "  float *gpuA = CopyToGpuMem(a);\n",
        "  float *gpuB = CopyToGpuMem(b);\n",
        "  float *gpuC = CopyToGpuMem(c);\n",
        "  float *gpuD = CopyToGpuMem(d);\n",
        "  uint8_t *imageGpu = CopyToGpuMem<uint8_t>(image);\n",
        "\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "  cv::Mat preprocessedCpu = preprocessCpu(image);\n",
        "  auto stop = std::chrono::high_resolution_clock::now();\n",
        "  int processingTimeCpu = std::chrono::duration_cast<std::chrono::microseconds>(stop - start).count();\n",
        "  std::cout << \"Preprocessing (CPU) - processing time: \" << processingTimeCpu << \" us\" << std::endl;     \n",
        "\n",
        "  float *preprocessedGpu = nullptr;\n",
        "  CUDA_ASSERT(cudaMalloc(&preprocessedGpu, image.total() * image.channels() * sizeof(float)));\n",
        "\n",
        "  start = std::chrono::high_resolution_clock::now();\n",
        "  preprocessGpu(imageGpu, image.total() * image.channels(), preprocessedGpu);\n",
        "  stop = std::chrono::high_resolution_clock::now();\n",
        "  int processingTimeGpu = std::chrono::duration_cast<std::chrono::microseconds>(stop - start).count();\n",
        "  std::cout << ((processingTimeGpu < processingTimeCpu) ? \"\\033[1m\\033[32m\" : \"\\033[1m\\033[31m\");\n",
        "  std::cout << \"Preprocessing (GPU) - processing time: \" << processingTimeGpu << \" us\" << \"\\033[0m\" << std::endl;\n",
        "\n",
        "  // Convert GPU to cv::Mat and compare results\n",
        "  cv::Mat preprocessedGpuMat(image.rows, image.cols, CV_32FC3);\n",
        "  CUDA_ASSERT(cudaMemcpy(preprocessedGpuMat.ptr<float>(), preprocessedGpu,\n",
        "      preprocessedGpuMat.total() * preprocessedGpuMat.channels() * sizeof(float),\n",
        "      cudaMemcpyDeviceToHost));\n",
        "  assert(compareImages(preprocessedGpuMat, preprocessedCpu));\n",
        "\n",
        "  start = std::chrono::high_resolution_clock::now();\n",
        "  auto disCpu = distanceCpu(a, b, c, d);\n",
        "  stop = std::chrono::high_resolution_clock::now();\n",
        "  processingTimeCpu = std::chrono::duration_cast<std::chrono::microseconds>(stop - start).count();\n",
        "  std::cout << \"Distance (CPU) = \" << disCpu[0] << \", \" << disCpu[1] << \", \" << disCpu[2]\n",
        "        << \" - processing time: \" << processingTimeCpu << \" us\" << std::endl;      \n",
        "\n",
        "  // Allocate intermediate GPU buffers\n",
        "  float *distance;\n",
        "  CUDA_ASSERT(cudaMalloc(&distance, 3 * sizeof(float)));\n",
        "\n",
        "  start = std::chrono::high_resolution_clock::now();\n",
        "  distanceGpu(gpuA, gpuB, gpuC, gpuD, distance, a.size());\n",
        "  stop = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  float disGpu[3];\n",
        "  CUDA_ASSERT(cudaMemcpy(disGpu, distance, sizeof(disGpu), cudaMemcpyDeviceToHost));\n",
        "  processingTimeGpu = std::chrono::duration_cast<std::chrono::microseconds>(stop - start).count();\n",
        "  std::cout << ((processingTimeGpu < processingTimeCpu) ? \"\\033[1m\\033[32m\" : \"\\033[1m\\033[31m\");\n",
        "  std::cout << \"Distance (GPU) = \" << disGpu[0] << \", \" << disGpu[1] << \", \" << disGpu[2]\n",
        "        << \" - processing time: \" << processingTimeGpu << \" us\" << \"\\033[0m\" << std::endl;\n",
        "\n",
        "  float epsilon = 10e-4;\n",
        "  assert(fabs(disCpu[0] - disGpu[0]) < epsilon);\n",
        "  assert(fabs(disCpu[1] - disGpu[1]) < epsilon);\n",
        "  assert(fabs(disCpu[2] - disGpu[2]) < epsilon);\n",
        "\n",
        "  cudaFree(gpuA);\n",
        "  cudaFree(gpuB);\n",
        "  cudaFree(gpuC);\n",
        "  cudaFree(imageGpu);\n",
        "  cudaFree(preprocessedGpu);\n",
        "  cudaFree(distance);\n",
        "}\n",
        "\n",
        "std::vector<float> loadData(const std::string &fileName) {\n",
        "  // open the file:\n",
        "  std::ifstream file(fileName, std::ios::binary);\n",
        "  assert(file.is_open());\n",
        "\n",
        "  // get its size:\n",
        "  file.seekg(0, std::ios::end);\n",
        "  std::size_t fileSize = file.tellg();\n",
        "  file.seekg(0, std::ios::beg);\n",
        "\n",
        "  // read the data:\n",
        "  std::vector<float> fileData(fileSize / sizeof(float));\n",
        "  file.read(reinterpret_cast<char *>(fileData.data()), fileData.size() * sizeof(float));\n",
        "  return fileData;\n",
        "}\n",
        "\n",
        "bool compareImages(const cv::Mat &a, const cv::Mat &b) {\n",
        "  cv::Mat diff;\n",
        "  cv::subtract(a, b, diff);\n",
        "  cv::Mat channels[3];\n",
        "  cv::split(diff, channels);\n",
        "  return (cv::countNonZero(channels[0]) == 0)\n",
        "      && (cv::countNonZero(channels[1]) == 0)\n",
        "      && (cv::countNonZero(channels[2]) == 0);\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/tmp8yprurzy/52561627-bf72-4ae6-98ed-366ce90ab4d7.cu(30): error: \"sum\" has already been declared in the current scope\n",
            "\n",
            "/tmp/tmp8yprurzy/52561627-bf72-4ae6-98ed-366ce90ab4d7.cu(50): error: argument of type \"const float *\" is incompatible with parameter of type \"float *\"\n",
            "\n",
            "/tmp/tmp8yprurzy/52561627-bf72-4ae6-98ed-366ce90ab4d7.cu(52): error: expected an expression\n",
            "\n",
            "/tmp/tmp8yprurzy/52561627-bf72-4ae6-98ed-366ce90ab4d7.cu(53): error: identifier \"sumCudaKernel\" is undefined\n",
            "\n",
            "/tmp/tmp8yprurzy/52561627-bf72-4ae6-98ed-366ce90ab4d7.cu(74): warning: variable \"THREADS_PER_BLOCK\" is used before its value is set\n",
            "\n",
            "4 errors detected in the compilation of \"/tmp/tmpxft_000004cb_00000000-8_52561627-bf72-4ae6-98ed-366ce90ab4d7.cpp1.ii\".\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}